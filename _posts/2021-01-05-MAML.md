---
layout: single
title:  "MAML"
date:   2021-01-04
categories: meta-learning
---
논문 ["Few-Shot Adaptive Gaze Estimation"](https://arxiv.org/pdf/1905.01941.pdf)에서는 gaze estimation의 개인화 요소를 few-shot learning으로 반영합니다. fine-tuning은 데이터도 많이 필요하고, 연산량도 많기 때문에 이를 대체하고자 meta learning을 활용한 few-shot learning을 시도한 것입니다. 결과는요? few-shot learning은 일반적인 fine-tuning보다 개인화에서 훨씬 더 좋은 성능을 보여주었습니다.

![compare](/assets/images/210105/compare.png)
*fine-tuning보다 더 낮은 에러를 기록한 few-shot learning(MAML)*

해당 논문에서 사용한 meta-learning 방법론이 바로 **MAML(Model-Agnostic Meta-Learning)** 입니다(Model-Agnostic하다는 것은, gradient descent로 학습가능한 모든 Model에 적용가능하기 때문에 붙은 이름입니다.). MAML의 목표를 가장 간단히 보여주는 것이 아래 그림입니다.

![MAML](/assets/images/210105/MAML.png)
*MAML의 동작 원리*

위 그림을 보면, 각 태스크에 최적화된 파라미터들이 있을 때, 그 파라미터들 중 어느 하나로 치우치는 것이 아니라, 적당히 그 가운데로 파라미터를 갱신하는 양상을 확인할 수 있습니다. 이처럼 태스크가 여러 개 존재할 때, **모든 태스크에 가장 general하게 adaptable한 weight**를 찾는 것이 MAML의 목표입니다. 아래는 일반적인 MAML의 학습 알고리즘입니다.

![algorithm](/assets/images/210105/algorithm.png)

상당히 직관적인 학습 방법입니다. K개의 sample로 학습했을 때, 얼마나 그 task에 잘 adapt하는지를 계산해서, loss로 사용하여 backprop합니다. 있는 그대로 "몇 개의 sample로 학습했을 때, 그 task에 대해서 얼마나 잘 학습을 할 수 있는가?"의 문제를 명시적으로 접근한 것입니다. 서두에 언급한 논문에서 사용한 방법은 위 알고리즘의 특수한 경우로, 각 subject를 하나의 task로 보는, batch size가 1인 경우입니다.


## 생각
Meta learning에 대해 learn to learn 이라는 추상적인 개념만 가지고 있었는데, 마침 관심분야에서 활발하게 연구되고 있는 few shot learning과 접목되어 재미있게 읽었습니다. 제가 어깨너머로 듣던 "learn to learn" 보다는 weight 중심의, 약간은 수학적인 접근인 것 같기는 합니다만, 직관적인 접근 방법이 상당히 흥미로웠습니다. (학습 방법을 배운다기보다는, 기반 지식을 확보하는 느낌처럼 다가왔습니다.)   
이후에 발전된 형태로 FOMAML, Reptile 등 다양한 meta-learning 방법론이 제시되었다고 하는데, 수학적인 이해가 필요할 것 같아서 나중에 꼼꼼히 읽어보고 리뷰하고 싶습니다!
